{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOYJBhhBnurnLKEKOjZTzGG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["HIMANI ARORA\n","22070122079","\n","GARGI MITTAL\n","22070122064","\n","MEET GOLANI"],"metadata":{"id":"_AhOsBV2QDTu"}},{"cell_type":"markdown","source":["# Pneumonia Classification using Chest X-rays based on Convolutional Neural Nets with Hyper-parameter tuning for CNN\n","\n"],"metadata":{"id":"H0C5cTx0QNxu"}},{"cell_type":"markdown","source":["##Objectives:\n","\n","1. Study the Pueunmonia dataset.\n","\n","2. Study CNN in detail with its hyperparameter tuning.\n","\n","3. Implement the same with google colab."],"metadata":{"id":"RK6jkxJjQR6n"}},{"cell_type":"markdown","source":["# Theory:\n","### Chest X-Rays Dataset\n","1. Pneumonia is a severe lung infection that causes inflammation in the air sacs of the lungs, leading to serious complications and even death, particularly in children and the elderly. Early detection and diagnosis of pneumonia are critical for effective treatment. One widely used method for diagnosis is through chest X-ray imaging, where radiologists look for signs of infection in the lungs.\n","\n","2. The dataset provided by Paul Timothy Mooney, titled \"Chest X-ray Pneumonia\", is a collection of X-ray images categorized into two groups: Pneumonia and Normal.  \n","\n","3. **Dataset Overview:**\n","\n","* The dataset, available on Kaggle under the title \"Chest X-ray Pneumonia\", contains chest X-ray images for the detection of pneumonia.\n","* These images are classified into two categories:    \n","Normal: X-ray images without pneumonia.  \n","Pneumonia: X-ray images with pneumonia.  \n","\n","* This dataset provides a platform for applying deep learning techniques, particularly Convolutional Neural Networks (CNNs), to develop models that can automatically classify X-ray images and help in the early diagnosis of pneumonia.\n","\n","4. **Dataset Specifications:**  \n","Number of Images: Approximately 5,863 X-ray images.\n","\n","5. **Classes:**    \n","Normal: Chest X-rays without pneumonia.    \n","Pneumonia: Chest X-rays with pneumonia, further subdivided into bacterial and viral pneumonia.    \n","Image Shape: All images are in JPEG format and grayscale.\n"],"metadata":{"id":"C2Zdp2h_Qv9L"}},{"cell_type":"markdown","source":["### **Hyperparameters in Convolutional Neural Networks (CNNs)**\n","\n","Hyperparameters in Convolutional Neural Networks (CNNs) are configuration settings that define the architecture and training process of the network. Unlike parameters that the network learns during training, such as weights and biases, hyperparameters are set before the training process begins and directly influence the model's performance and computational efficiency.\n","\n","\n","### **1. Learning Rate (α):**\n","\n","The learning rate determines how much the model's weights are adjusted in response to the gradient during each backpropagation step. It is one of the most important hyperparameters in any deep learning model.\n","\n","- **High Learning Rate**: Leads to faster convergence but risks overshooting the optimal solution.\n","- **Low Learning Rate**: Results in slower convergence, but it allows the model to explore the loss surface more carefully, reducing the risk of overshooting.\n","\n","The learning rate is typically selected via experimentation, and techniques like **learning rate schedules** or **adaptive learning rates** (used in optimizers like Adam) are commonly used to adjust it dynamically during training.\n","\n","\n","\n","### **2. Batch Size:**\n","\n","Batch size defines the number of samples processed before the model's weights are updated.\n","\n","- **Small Batch Size**: Offers a more granular update of weights and often leads to better generalization. However, it results in noisier gradient estimates and slower training.\n","- **Large Batch Size**: Allows for faster training due to more stable gradient estimates, but it can lead to suboptimal performance and poor generalization.\n","\n","Typical values for batch size range from 16 to 128, depending on available computational resources and the size of the dataset.\n","\n","\n","\n","### **3. Number of Epochs:**\n","\n","The number of epochs specifies how many complete passes through the training dataset the model will make during training. Too few epochs may result in **underfitting** (where the model doesn't learn enough patterns), while too many epochs may lead to **overfitting** (where the model learns even the noise in the training data).\n","\n","- **Early Stopping**: This is often used to stop training once the model's performance on the validation set stops improving, thus preventing overfitting.\n","\n","\n","### **4. Filter Size (Kernel Size):**\n","\n","In a convolutional layer, the filter or kernel size refers to the height and width of the filters used to perform the convolution operation. Common filter sizes include **3x3**, **5x5**, or **7x7**.\n","\n","- **Smaller Filters (e.g., 3x3)**: Capture finer details and are typically stacked in deeper layers of the network. They are computationally cheaper and preserve spatial information better.\n","- **Larger Filters (e.g., 7x7)**: Capture more global features but can lead to loss of fine detail and are computationally more expensive.\n","\n","\n","\n","### **5. Number of Filters (Depth of Convolutional Layer):**\n","\n","The number of filters in a convolutional layer (also known as the depth or channels) determines how many feature maps are learned at each layer. Increasing the number of filters allows the model to learn more features, but it also increases computational complexity.\n","\n","- **Shallow Layers**: Fewer filters (e.g., 32 or 64) are typically used in the initial layers to capture basic features like edges and textures.\n","- **Deeper Layers**: More filters (e.g., 128, 256, or more) are used in later layers to capture more complex features such as patterns and objects.\n","\n","\n","\n","### **6. Stride:**\n","\n","Stride refers to how much the filter moves across the input image during the convolution operation.\n","\n","- **Stride = 1**: Moves the filter one pixel at a time. This results in highly detailed feature maps but increases the size of the output.\n","- **Stride > 1**: Reduces the spatial dimensions of the feature maps by skipping pixels. This reduces the computational load but may result in loss of spatial information.\n","\n","Common stride values are 1 or 2, depending on the desired output size and computational constraints.\n","\n","\n","\n","### **7. Padding:**\n","\n","Padding is the process of adding extra pixels (usually zeros) around the edges of the input image before applying the convolution operation. Padding is used to control the output size of the convolutional layer.\n","\n","- **Valid Padding (No Padding)**: Reduces the spatial dimensions of the input image by not adding any padding. This often leads to smaller feature maps.\n","- **Same Padding**: Adds padding in such a way that the output size is the same as the input size, which allows for more control over the depth of the network.\n","\n","\n","\n","### **8. Pooling Size:**\n","\n","Pooling layers (e.g., max pooling or average pooling) are used to downsample the feature maps, reducing the spatial dimensions while retaining important features.\n","\n","- **Max Pooling**: Takes the maximum value from a patch of the feature map.\n","- **Average Pooling**: Takes the average of the values in the patch.\n","\n","Pooling sizes are usually 2x2 or 3x3, and pooling helps in reducing the number of parameters and computation while also controlling overfitting.\n","\n","\n","\n","### **9. Dropout Rate:**\n","\n","Dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of the neurons to zero during each training iteration.\n","\n","- **Dropout Rate (p)**: Specifies the fraction of neurons to drop (e.g., p = 0.5 means 50% of the neurons are randomly ignored during each training step).\n","- **Common Values**: Dropout rates typically range from 0.2 to 0.5, with higher dropout rates used in dense layers to improve generalization.\n","\n","\n","### **10. Optimizer:**\n","\n","The optimizer determines how the network's weights are updated during training. Common optimizers include:\n","\n","- **SGD (Stochastic Gradient Descent)**: The most basic optimizer, with momentum to help accelerate the convergence.\n","- **Adam (Adaptive Moment Estimation)**: Combines the benefits of SGD with adaptive learning rates and momentum, making it a popular choice for most deep learning models.\n","- **RMSProp**: Another adaptive learning rate optimizer that works well for recurrent neural networks (RNNs) but is also useful for CNNs.\n","\n","The choice of optimizer can significantly affect training speed and convergence.\n","\n","\n","### **11. Activation Function:**\n","\n","The activation function introduces non-linearity into the network, allowing it to learn complex patterns.\n","\n","- **ReLU (Rectified Linear Unit)**: The most commonly used activation function in CNNs, defined as \\( f(x) = \\max(0, x) \\). It speeds up convergence and mitigates the vanishing gradient problem.\n","- **Sigmoid**: Often used in the output layer for binary classification, but less common in hidden layers due to slower convergence.\n","- **Softmax**: Typically used in the output layer for multi-class classification problems to normalize output values into probabilities.\n","\n","\n","\n","### **12. Weight Initialization:**\n","\n","Weight initialization helps to prevent issues like vanishing or exploding gradients. Common initialization methods include:\n","\n","- **He Initialization**: Ideal for ReLU activation functions.\n","- **Xavier Initialization**: Useful for tanh or sigmoid activations.\n","\n","Proper weight initialization can lead to faster convergence during training.\n","\n","\n","\n","Hyperparameters in CNNs play a crucial role in determining the model's performance and efficiency. These parameters, including learning rate, batch size, number of epochs, filter size, and more, need to be carefully tuned to strike the right balance between learning capacity and computational efficiency. By conducting hyperparameter optimization, models can achieve better accuracy, reduced loss, and improved generalization to unseen data."],"metadata":{"id":"Vcad03qhQUH_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YkUx9fJbPW8C","executionInfo":{"status":"ok","timestamp":1729668688283,"user_tz":-330,"elapsed":138577,"user":{"displayName":"Simrann.Dabrai Btech2022","userId":"12877605997032749511"}},"outputId":"442bee9e-6510-4927-89bb-92d745b04d21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n","License(s): other\n","Downloading chest-xray-pneumonia.zip to /content\n","100% 2.29G/2.29G [01:49<00:00, 17.2MB/s]\n","100% 2.29G/2.29G [01:49<00:00, 22.4MB/s]\n"]}],"source":["# Install Kaggle API\n","!pip install kaggle -qq\n","# Make a directory for Kaggle and upload the kaggle.json file\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","# Set permissions for the Kaggle API token\n","!chmod 600 ~/.kaggle/kaggle.json\n","# Download the Pneumonia dataset from Kaggle\n","!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia --unzip\n"]},{"cell_type":"code","source":["!pip install keras-tuner -qq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1UF0O4ZR73k","executionInfo":{"status":"ok","timestamp":1729668693872,"user_tz":-330,"elapsed":3891,"user":{"displayName":"Simrann.Dabrai Btech2022","userId":"12877605997032749511"}},"outputId":"8458d38c-bad5-411b-9128-ae75ec66a142"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","train_dir = '/content/chest_xray/train'\n","val_dir = '/content/chest_xray/val'\n","test_dir = '/content/chest_xray/test'"],"metadata":{"id":"ka0ehdSgSQ5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image data generators for data augmentation\n","train_datagen = ImageDataGenerator(\n","rescale=1./255,\n","rotation_range=40,\n","width_shift_range=0.2,\n","height_shift_range=0.2,\n","shear_range=0.2,\n","zoom_range=0.2,\n","horizontal_flip=True,\n","fill_mode='nearest'\n",")\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","# Data generators\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","target_size=(150, 150),\n","batch_size=32,\n","class_mode='binary'\n",")\n","val_generator = val_datagen.flow_from_directory(\n","val_dir,\n","target_size=(150, 150),\n","batch_size=32,\n","class_mode='binary'\n",")\n","test_generator = test_datagen.flow_from_directory(\n","test_dir,\n","target_size=(150, 150),\n","batch_size=32,\n","class_mode='binary'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esYDKDBPSXDX","executionInfo":{"status":"ok","timestamp":1729668999081,"user_tz":-330,"elapsed":671,"user":{"displayName":"Simrann.Dabrai Btech2022","userId":"12877605997032749511"}},"outputId":"2ee0745e-7395-4207-ab5f-276aa76bbec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5216 images belonging to 2 classes.\n","Found 16 images belonging to 2 classes.\n","Found 624 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["import keras_tuner as kt\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","def build_model(hp):\n","  model = Sequential()\n","  # Convolutional layers\n","  model.add(Conv2D(\n","  filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n","  kernel_size=(3, 3),\n","  activation='relu',\n","  input_shape=(150, 150, 3)\n","  ))\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Conv2D(\n","  filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n","  kernel_size=(3, 3),\n","  activation='relu'\n","  ))\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Conv2D(\n","  filters=hp.Int('conv_3_filters', min_value=128, max_value=512, step=128),\n","  kernel_size=(3, 3),\n","  activation='relu'\n","  ))\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Flatten())\n","  model.add(Dense(\n","  units=hp.Int('dense_units', min_value=128, max_value=512, step=64),\n","  activation='relu'\n","  ))\n","  model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n","  model.add(Dense(1, activation='sigmoid'))\n","  model.compile(\n","  optimizer=hp.Choice('optimizer', values=['adam', 'sgd']),\n","  #optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","  loss='binary_crossentropy',\n","  metrics=['accuracy']\n","  )\n","  return model\n"],"metadata":{"id":"GGfNBm-lTnw7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNRQ8ztCQQwE"},"source":["This code defines a CNN model for hyperparameter tuning using Keras Tuner. It has three convolutional layers, with the number of filters for each layer being tunable between defined ranges (`conv_1_filters`, `conv_2_filters`, `conv_3_filters`). After each convolutional layer, there's a max pooling layer. The model is flattened and followed by a dense layer, where the number of units (`dense_units`) and dropout rate (`dropout_rate`) are tunable. The optimizer is also tunable, allowing for either 'adam' or 'sgd', and the model is compiled for binary classification with the `binary_crossentropy` loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87FM5dHr2f9D","outputId":"88869bfc-1dcc-4f39-ad80-3403f814728e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 10 Complete [00h 12m 11s]\n","val_accuracy: 0.8541666666666666\n","\n","Best val_accuracy So Far: 0.875\n","Total elapsed time: 02h 05m 06s\n","Best Hyperparameters: {'conv_1_filters': 128, 'conv_2_filters': 64, 'conv_3_filters': 128, 'dense_units': 384, 'dropout_rate': 0.4, 'optimizer': 'adam'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["tuner = kt.RandomSearch(\n","  build_model,\n","  objective='val_accuracy',\n","  max_trials=10, # Number of different hyperparameter combinations to try\n","  executions_per_trial=3, # Number of models to build and evaluate per trial\n","  directory='my_dir',\n","  project_name='pneumonia_cnn',\n","  seed = 2\n",")\n","\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","\n","# Search for the best hyperparameters\n","tuner.search(\n","  train_generator,\n","  epochs=3,\n","  validation_data=val_generator,\n","  callbacks=[stop_early]\n",")\n","\n","# Get the best model and hyperparameters\n","best_model = tuner.get_best_models(num_models=1)[0]\n","best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"Best Hyperparameters: {best_hyperparameters.values}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WVy47zA3kuZ","outputId":"28f7a55f-209d-4cde-a4b9-8a0b3d8986f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 441ms/step - accuracy: 0.6666 - loss: 0.6589\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.6538461446762085\n"]}],"source":["test_loss, test_acc = best_model.evaluate(test_generator)\n","print(f'Test Accuracy: {test_acc}')\n","best_model.save('best_pneumonia_cnn_model.h5')"]},{"cell_type":"markdown","source":["The code executes multiple runs with different hyperparameter combinations, aiming to optimize the model's performance. After running the models for 3 epochs over 4 iterations, it saves the best-performing model based on validation accuracy. While the validation accuracy is about 85%, the testing accuracy is significantly lower at 65%, possibly indicating overfitting or a mismatch in data representation between the training and testing datasets.\n","\n","### Inferences:\n","1. **Overfitting Likely Occurred**: The large gap between validation accuracy (85%) and testing accuracy (65%) suggests that the model may have learned patterns specific to the training/validation data that do not generalize well to unseen test data.\n","   \n","2. **Potential Data Issues**: The discrepancy between validation and testing accuracy could also imply issues with the data split or sampling methods, where the test set may not accurately represent the distribution of the training/validation set.\n","\n","3. **Model Performance on Test Data**: Despite identifying hyperparameters that perform well on validation data, the lower testing accuracy reveals that the model may still need improvements, such as regularization, better data preprocessing, or different architectures.\n","\n","4. **Ideal Hyperparameters Identified for the Validation Set**: Regardless of the test set performance, the experimentation has successfully identified a set of hyperparameters that consistently return the best validation accuracy for this particular model and dataset.\n","\n","5. **Future Improvements**: Addressing overfitting through techniques like cross-validation, dropout, or data augmentation may help improve generalization to the test data."],"metadata":{"id":"ZGgrEQj0QzYo"}}]}
